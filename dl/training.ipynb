{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import random\n",
    "from random import shuffle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "random.seed(2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T20:12:13.295198800Z",
     "start_time": "2023-11-19T20:12:13.290691300Z"
    }
   },
   "id": "bc71a105637e6a8d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the Data "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38b0220883093934"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                                          file_broken\nfile_perfect                                                                                         \nBach_Bwv10661069_Orchestral_Suites_Bwv1067_Orch...  Bach_Bwv10661069_Orchestral_Suites_Bwv1067_Orc...\nBach_Bwv10661069_Orchestral_Suites_Bwv1067_Orch...  Bach_Bwv10661069_Orchestral_Suites_Bwv1067_Orc...\nBach_Bwv10661069_Orchestral_Suites_Bwv1067_Orch...  Bach_Bwv10661069_Orchestral_Suites_Bwv1067_Orc...\nBach_Bwv10661069_Orchestral_Suites_Bwv1067_Orch...  Bach_Bwv10661069_Orchestral_Suites_Bwv1067_Orc...\nBach_Bwv10661069_Orchestral_Suites_Bwv1067_Orch...  Bach_Bwv10661069_Orchestral_Suites_Bwv1067_Orc...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_broken</th>\n    </tr>\n    <tr>\n      <th>file_perfect</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Bach_Bwv10661069_Orchestral_Suites_Bwv1067_Orchestral_Suite_n2_1mov_12.png</th>\n      <td>Bach_Bwv10661069_Orchestral_Suites_Bwv1067_Orc...</td>\n    </tr>\n    <tr>\n      <th>Bach_Bwv10661069_Orchestral_Suites_Bwv1067_Orchestral_Suite_n2_1mov_12.png</th>\n      <td>Bach_Bwv10661069_Orchestral_Suites_Bwv1067_Orc...</td>\n    </tr>\n    <tr>\n      <th>Bach_Bwv10661069_Orchestral_Suites_Bwv1067_Orchestral_Suite_n2_1mov_12.png</th>\n      <td>Bach_Bwv10661069_Orchestral_Suites_Bwv1067_Orc...</td>\n    </tr>\n    <tr>\n      <th>Bach_Bwv10661069_Orchestral_Suites_Bwv1067_Orchestral_Suite_n2_1mov_12.png</th>\n      <td>Bach_Bwv10661069_Orchestral_Suites_Bwv1067_Orc...</td>\n    </tr>\n    <tr>\n      <th>Bach_Bwv10661069_Orchestral_Suites_Bwv1067_Orchestral_Suite_n2_1mov_12.png</th>\n      <td>Bach_Bwv10661069_Orchestral_Suites_Bwv1067_Orc...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_file = \"../dataset/pairs/perfect_broken_index.pkl\"\n",
    "path_broken = \"../dataset/pairs/broken\"\n",
    "path_perfect = \"../dataset/pairs/perfect\"\n",
    "\n",
    "df = pd.read_pickle(index_file)\n",
    "df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T20:12:14.500602900Z",
     "start_time": "2023-11-19T20:12:14.487697200Z"
    }
   },
   "id": "2cc11a140dce3eee"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((3508, 2480)), transforms.ToTensor(), transforms.Normalize(0.5, 0.5)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T20:12:19.979640Z",
     "start_time": "2023-11-19T20:12:19.974799600Z"
    }
   },
   "id": "95fa0eb84588d520"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 7\u001B[0m\n\u001B[0;32m      3\u001B[0m max_images \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m500\u001B[39m\n\u001B[0;32m      5\u001B[0m images_broken_perfect \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m----> 7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m file_perfect \u001B[38;5;129;01min\u001B[39;00m \u001B[43mdf\u001B[49m\u001B[38;5;241m.\u001B[39mindex:\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;66;03m# print(\"\\r\", \"{:02d}\".format(max_images), end=\"\")\u001B[39;00m\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m max_images \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m     11\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "max_images = 500\n",
    "\n",
    "images_broken_perfect = []\n",
    "\n",
    "for file_perfect in df.index:\n",
    "    # print(\"\\r\", \"{:02d}\".format(max_images), end=\"\")\n",
    "    \n",
    "    if max_images == 0:\n",
    "        break\n",
    "    \n",
    "    files_broken = df.loc[file_perfect, \"file_broken\"]\n",
    "    \n",
    "    if files_broken is None:\n",
    "        continue\n",
    "        \n",
    "    file_broken = files_broken.values[random.randint(0, len(files_broken.values)-1)] # Random \"Broken\" image\n",
    "    \n",
    "    image_broken = Image.open(f\"{path_broken}/{file_broken}\").convert('L')\n",
    "    image_perfect = Image.open(f\"{path_perfect}/{file_perfect}\").convert('L')\n",
    "    \n",
    "    image_broken = transform(image_broken)\n",
    "    image_perfect = transform(image_perfect)\n",
    "    \n",
    "    images_broken_perfect.append((image_broken, image_perfect)) \n",
    "    \n",
    "    \n",
    "    \n",
    "    max_images -= 1\n",
    "\n",
    "\n",
    "print(\"\\rDone\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T20:24:28.485407Z",
     "start_time": "2023-11-19T20:24:28.364963500Z"
    }
   },
   "id": "b4c643c5ae49d5c1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(images_broken_perfect[0][0].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T20:10:15.937069800Z",
     "start_time": "2023-11-19T20:10:15.925069300Z"
    }
   },
   "id": "e147855c8b76c416"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def revoke_preprocessing(image: [torch.Tensor, np.ndarray]):\n",
    "    if type(image) == torch.Tensor:\n",
    "        image = image.squeeze().numpy()\n",
    "        \n",
    "    image = (0.5 *  image + 0.5) * 255\n",
    "    return Image.fromarray(image).convert('RGB')\n",
    "    \n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(revoke_preprocessing(images_broken_perfect[0][0]))\n",
    "ax1.set_title(\"Broken\")\n",
    "ax2.imshow(revoke_preprocessing(images_broken_perfect[0][1]))\n",
    "ax2.set_title(\"Perfect\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-19T20:10:15.926069400Z"
    }
   },
   "id": "8dab6419b72422b8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Building train test and validation set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3f9567e9b77c093"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9ec3e93eb4157474"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_test_val = (0.8, 0.1, 0.1)\n",
    "limits = [int(x * len(images_broken_perfect)) for x in train_test_val]\n",
    "\n",
    "shuffle(images_broken_perfect)\n",
    "\n",
    "train_dataset = images_broken_perfect[:limits[0]]\n",
    "test_dataset = images_broken_perfect[limits[0]:limits[0] + limits[1]]\n",
    "valid_dataset = images_broken_perfect[limits[0] + limits[1]:]\n",
    "\n",
    "print(\"Sizes: train\", len(train_dataset), \", test\", len(test_dataset), \", validation\", len(valid_dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-19T20:10:15.927069300Z"
    }
   },
   "id": "ecf444620bddb932"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "train_loader = DataLoader(train_dataset)\n",
    "test_loader = DataLoader(test_dataset)\n",
    "valid_loader = DataLoader(valid_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-19T20:10:15.928069600Z"
    }
   },
   "id": "70a51c11f76590e4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5c542b1e72038ee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Denoiser(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # defining the encoder\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1, stride=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1, stride=1)\n",
    "        \n",
    "        # defining pooling  \n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        # defining the decoder\n",
    "        self.conv2d_1 = nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1)\n",
    "        self.conv2d_2 = nn.Conv2d(64, 32, kernel_size=3, padding=1, stride=1)\n",
    "        self.conv2d_3 = nn.Conv2d(32, 1, kernel_size=3, padding=1, stride=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # passing the image through encoder\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # passing the encoded part through decoder\n",
    "        x = F.relu(self.conv2d_1(x))\n",
    "        x = F.interpolate(x, scale_factor=2, mode='nearest')\n",
    "        x = F.relu(self.conv2d_2(x))\n",
    "        x = F.interpolate(x, scale_factor=2, mode='nearest')\n",
    "        x = F.sigmoid(self.conv2d_3(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = Denoiser()\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-19T20:10:15.929069200Z"
    }
   },
   "id": "5f002eae9afb905e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# defining the loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# defining the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-19T20:10:15.930069500Z"
    }
   },
   "id": "9e94b70df78e2a8f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('Cuda Available..Training on GPU')\n",
    "    torch.backends.cudnn.benchmark =  True\n",
    "    torch.backends.cudnn.enabled =  True\n",
    "    model = model.cuda()\n",
    "else:\n",
    "\tprint('CUDA not available..Traning on CPU')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-19T20:10:15.930069500Z"
    }
   },
   "id": "ccca534872fa438f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "training_loss = 0\n",
    "min_valid_loss = np.Inf\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(cuda_available)\n",
    "\n",
    "save_file = \"save/model.pt\"\n",
    "\n",
    "for e in range(epochs):\n",
    "    print(\"Training\")\n",
    "    i = 0\n",
    "    \n",
    "    for images, targets in train_loader:\n",
    "        print(\"\\rTrain\", i, end=\"\")\n",
    "        \n",
    "        if cuda_available:\n",
    "            images, targets = images.cuda(), targets.cuda()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_loss += loss.item()\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    print(\"Validating\")\n",
    "    i = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        valid_loss = 0\n",
    "        \n",
    "        for images, targets in valid_loader:\n",
    "            print(\"\\rValidate\", i, end=\"\")\n",
    "            \n",
    "            if cuda_available:\n",
    "                images, targets = images.cuda(), targets.cuda()\n",
    "        \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            valid_loss += loss.item()\n",
    "            \n",
    "            i+=1 \n",
    "    \n",
    "        if valid_loss < min_valid_loss:\n",
    "            print('Loss Decreased..({:.3f} -> {:.3f})  Saving Model..'.format(valid_loss, min_valid_loss))\n",
    "            torch.save(model.state_dict(), save_file)\n",
    "            min_valid_loss = valid_loss/len(valid_loader)\n",
    "            \n",
    "    print('Epoch: {}/{} -- Training Loss: {:.3f} -- Testing Loss: {:.3f}'.format(e+1, epochs, training_loss/len(train_loader), \\\n",
    "                                                                                 valid_loss/len(valid_loader)))\n",
    "\n",
    "    training_loss = 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-19T20:10:15.931069300Z"
    }
   },
   "id": "4b6a848b9c96a24a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#model = Denoiser()\n",
    "#model.load_state_dict(torch.load(\"save/model.pt\" ))\n",
    "#model = model.cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-19T20:10:15.931069300Z"
    }
   },
   "id": "24b36ccd339caae"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "test_pairs = []\n",
    "\n",
    "for images, targets in test_loader:\n",
    "    if cuda_available:\n",
    "        images, targets = images.cuda(), targets.cuda()\n",
    "    \n",
    "    predictions = model(images)\n",
    "    \n",
    "    score = criterion(predictions, targets)\n",
    "    \n",
    "    test_pairs.append((images, targets, predictions.cpu(), score.cpu()))\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-19T20:10:15.932069500Z"
    }
   },
   "id": "9e029450998afc2f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"import gc\n",
    "\n",
    "# model.cpu()\n",
    "del score #, ,  # , , \n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-19T20:10:15.933069700Z"
    }
   },
   "id": "eb45541bf575fd34"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
